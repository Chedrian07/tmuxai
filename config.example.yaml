# Set to true to log full AI messages sent and received. Dest: ~/.config/tmuxai/debug/
debug: false

# Maximum context size in tokens, reaching 80% triggers squashing
max_context_size: 100000

# Maximum number of lines to capture during each message
max_capture_lines: 200

# Wait interval when exec pane is considered busy (used in observe and watch modes)
wait_interval: 5

models:
  gpt4:
    provider: "openai"
    model: "gpt-4"
    api_key: "sk-XXXXXXXXX"
    base_url: "https://api.openai.com/v1"

  claude-sonnet:
    provider: "openrouter"
    model: "anthropic/claude-3.5-sonnet"
    api_key: "sk-or-XXXXXXXXX"

  gemini-flash:
    provider: "openrouter"
    model: "google/gemini-2.5-flash-preview"
    api_key: "sk-or-v1-XXXXXXXXX"
    base_url: "https://openrouter.ai/api/v1"

  local-llama:
    provider: "openrouter"
    model: "meta-llama/llama-3.1-8b-instruct:free"
    api_key: "sk-or-XXXXXXXXX"

  azure-gpt4:
    provider: "azure"
    model: "gpt-4o"
    api_key: "your-azure-openai-api-key"
    api_base: "https://your-resource.openai.azure.com/"
    api_version: "2025-04-01-preview"
    deployment_name: "gpt-4o"

default_model: "gemini-flash"  # Which model to use by default

# Confirm before AI executes a command
exec_confirm: true

# Confirm before AI sends a key
send_keys_confirm: true

# Confirm before AI pastes a multiline text
paste_multiline_confirm: true

whitelist_patterns:
  - '^find(\s+.*)?$'
  - '^pwd\s*$'
  - '^cat(\s+.*)?$'

blacklist_patterns:
  - 'rm\s+'
  - 'mv\s+'
  - 'dd\s+'

# Prompts customization, see prompts.go for more details
prompts:
  base_system: |
    xxx

  chat_assistant: |
     xxx

  chat_assistant_prepared: |
     xxx

  watch: |
     xxx
